[["index.html", "FMISD13207 Cloud Security Technologies Introduction", " FMISD13207 Cloud Security Technologies Kstutis Daugla 2022-04-17 Introduction Information Security Fundamentals (information security problematics, classification and evolution of threats, identification, authentication, access control, security principals, strategies, models, taxonomies and antologies); Cryptography (simetric and public key cryptography, DES, AES, RSA. stream ciphers, cryptographic protocols, authentication, electronic signature, management of electronic identity); Network Security (routing, firewalls, VPN, web security, network perimeter protection, host-level protection, authentication technologies); Attacking Information Technology Systems (attack types, real-life case studies, intrusion detection, formal analysis techniques); Information Security Technologies (antivirus, IDS, host and perimeter protection systems, Honeypots); Implementing Effective Information Security Programs (legal, regulatory and privacy issues, security standarts, security best practices, security policy). The underlying concept of cloud computing was introduced way back in 1960s by John McCarthy in his book, The challenge of the Computer Utility. His opinion was that computation may someday be organized as a public utility. The rest became history and the majority of the software used now is running in the cloud seamlessly (Surbiryala and Rong 2019). The history of the cloud - image source https://itchronicles.com/ Cloud can solve a lot of problems nowadays - starting with reduced cost, enhanced security, and flexible approach (Srivastava and Khan 2018) up to sustainability (Parthasarathy and Kumar 2012) and accessibility around the world. Continuous Integration and Deployment (CI/CD) is easier than even treating now only the applications, but the whole infrastructure as code. This leads to enhanced productivity and cost optimization (Garg and Garg 2019). Is there anything revolutionary in the cloud offerings today? Definitely, no - people used these capabilities for ages. The only difference is the scale and popularity these days. Cloud services usually are grouped into three categories: SaaS (Software as a service) is a software distribution model in which a cloud provider hosts applications and makes them available to end-users over the internet PaaS (Platform as a service) is a complete development and deployment environment in the cloud, with resources that enable you to deliver everything from simple cloud-based apps to sophisticated, cloud-enabled enterprise applications IaaS (Infrastructure as a service) is a type of cloud computing service that offers essential compute, storage, and networking resources on-demand, on a pay-as-you-go basis IaaS vs PaaS vs SaaS - image source https://www.bigcommerce.com/blog/saas-vs-paas-vs-iaas/ However, despite the gain achieved from cloud computing, organizations are slow in fully accepting it due to security issues and challenges associated with it (Bairagi and Bang 2015). However, almost every cloud-ready company uses the public cloud (97%) to some extent leaving hybrid cloud setup the dominant one (78%). Companies rarely use public or private cloud alone (19% vs 2% respectively). According to Forbes, there are now 77 % of organizations, having one or some parts of their systems in the cloud. Cloud service providers follow a shared security responsibility model, which means that your security team retains some security duties as you migrate applications, data, containers, and workloads to the cloud, while the provider takes part, but not all, of the responsibility. Clearly defining your duties from those of your providers is critical for minimizing the risk of introducing vulnerabilities into your public, hybrid, or multi-cloud systems, as shown in the graph below. Shared responsibility in the cloud - image source www.microsoft.com Worlds Biggest Data Breaches &amp; Hacks - image source https://www.informationisbeautiful.net/visualizations/worlds-biggest-data-breaches-hacks/ References "],["type-of-attacks.html", "Chapter 1 Type of attacks", " Chapter 1 Type of attacks The literature has examined a variety of security flaws(Humayun et al. 2020). To aid readers in comprehending some of the most prevalent cyber security weaknesses, the following are detailed: The Vulnerabilities that a Business can Experience - image source https://blog.ecosystm360.com/cyber-attacks-threats-risks/ Malware. For the previous decade, malware attacks have been the most serious cyber security danger to many enterprises (Lim and Lukito 2013). Malware The attacker uses malicious software to gain unauthorized access to computer systems by exploiting their security flaws. Malware is motivated by an extreme financial or political gain, which increases an attackers drive to compromise as many network devices as possible in order to accomplish their harmful goals. Viruses, worms, trojans, backdoors and adware are but a few examples that fall under the umbrella of malware (Mokoena and Zuva 2017). DDoS. Cyber security is comprised on three essential components: confidentiality, integrity, and availability. Denial of Service (DoS) attacks and their version, Distributed Denial of Service (DDoS), are conceivable threats that deplete system resources, rendering them inaccessible to authorized users, hence breaching one of the security componentsavailability. DoS attacks on networks are widespread and have the potential to be catastrophic. Numerous types of DoS attacks have been identified thus far, and the most of them are extremely efficient at disrupting network connectivity. Both IPv4 and IPv6 are quite vulnerable to these attacks (Tripathi and Mehtre 2013). The frequency and scale of attacks have escalated in recent years, from a few megabytes to hundreds of gigabytes. It is difficult to identify these attacks efficiently due to changes in attack patterns or new forms of attacks (Vanitha, UMA, and Mahidhar 2017). Phishing is a very effective approach of cybercrime that criminals use to fool consumers and steal critical data. Since the first phishing assault was disclosed in 1990, the attack vector has grown into a more sophisticated attack vector. At the moment, phishing is regarded to be one of the most prevalent forms of fraud on the Internet. Phishing attacks can result in significant losses for their victims, including sensitive data, identity theft, businesses, and state secrets. (Alkhalil et al. 2021) SQL Injection Attack (SQLIA) is one of the most terrifying risks to web applications. Input validation flaws were the cause of a SQL injection attack on the web. SQLIA is a harmful behavior that exploits invalid SQL statements in order to exploit data-driven applications. This vulnerability allows an attacker to exploit manipulated input to gain access to the applications back-end databases through the applications interaction with them. As a result, the attacker can acquire access to the database without obtaining genuine clearance by introducing, changing, or removing key information (Hlaing and Khaing 2020). Man-in-the-middle. An attack in which an outsider or third party infiltrates the space between two online users while both users are unaware. In this instance, the malware primarily monitors and has the capacity to modify the information classified exclusively to these two people. Generally, it is referred to as a protocol to refer to an unauthorized user within the system who has the ability to view and modify the systems data without leaving a trail for the systems existing users (Javeed and MohammedBadamasi 2020). Cross-site scripting is a serious issue in Web Applications. With more connected devices that use a variety of Web Applications for various tasks, the potential of XSS assaults grows. By exploiting XSS vulnerabilities in Web applications, hackers can steal victims session details or other sensitive information(Nagarjun and Ahamad 2020). Zero-day exploit continue to be a significant security concern to enterprises. When a vendor becomes aware of a zero-day vulnerability, releasing a fix in a timely manner becomes a priority due to the possibility of zero-day exploits. However, we continue to lack knowledge on the factors that influence the time it takes for such vulnerabilities to be patched. It was discovered that while IT companies are quick to release timely updates for zero-day vulnerabilities that affect multiple vendors, products, and versions, vulnerabilities that require privileges and compromise confidentiality are less likely to be patched on time. (Roumani 2021). BEC (Business Email Compromise) is a sophisticated email fraud scheme that targets firms who deal with international suppliers and frequently transfer payments via wire transfers. BEC attacks are designed to eliminate security protections by capitalizing on flaws in human behavior and decision-making (Agazzi 2020). References "],["data-breach---case-study.html", "Chapter 2 Data Breach - Case Study 2.1 Twitch 2.2 Phizer 2.3 Citybee", " Chapter 2 Data Breach - Case Study 2.1 Twitch Twitch is a global community that comes together each day to create multiplayer entertainment: unique, live, unpredictable experiences created by the shared interactions of millions. Acquired by Amazon in 2014. UpGuard Security Rating - image source https://www.upguard.com/ Twitch recently suffered a data breach that, according to security analysts, may have revealed extensive information about the platforms computer code, security vulnerabilities, and payments to content providers. According to the source, the file contained the history of Twitchs source code; proprietary software development kits; an unreleased competitor to Steam, an online games store; programs used by Twitch to test its own security vulnerabilities; and a list of the amount of money earned by each of the sites streamers since 2019 NY Times - A potentially disastrous data breach hits Twitch, the livestreaming site As another security proffessional indicates in medium.com - Thoughts on the Twitch Breach: the attackers did not gain access through a zero-day vulnerability or a supply chain assault. Something existed in a state that was not compliant with or anticipated of it. It appears that the problem was a misconfiguration as this statement says something was in error. The attackers did not get in due to a zero-day or supply chain attack. Something existed in a non-compliant or expected state. It sounds as though a server was running something on an Internet-facing port. However, the exposed data could have existed in an S3 bucket and all we know is that a server entered an undesirable state, which resulted in data disclosure. The misconfiguration could be as simple as a server being allowed excessive permissions and access, or as complex as a server being exposed to the Internet when it should have been in a private network. Many people host their data on AWS and might be thinking, If Amazon cant keep data secure on AWS, who can?. Assess that you have zero-trust networking and permissions that provide persons and applications only the access they require. In an enterprise of that size, source control systems, if that is what was impacted in this case, should never be exposed directly to the entire Internet. Small enterprises may do so temporarily to stay afloat, but the majority of source control solutions allow you to restrict access to specific IP ranges. 2.2 Phizer Pfizer Inc., the worlds largest pharmaceutical company, has experienced a massive data breach, with patient information discovered exposed on unprotected cloud storage. The exposed data was discovered in a Google Cloud storage bucket that had been misconfigured. Hundreds of discussions between Pfizers automated customer service software and consumers who used the companys prescription pharmaceuticals, including Lyrica, Chantix, Viagra, and cancer medicines Ibrance and Aromasin, were included in the data. Along with sensitive medical information, the transcripts included full names, home addresses, and email addresses, which hackers could use to conduct highly effective phishing attempts against victims: Pfizer suffers huge data breach on unsecured cloud storage. It is evident that data storage in the public cloud has become the standard, and businesses of all sizes now face complicated identity and data management challenges. Capital One demonstrated, and Pfizer has confirmed, that even with the largest teams, funds, and skill sets, the public cloud is highly difficult. When corporate organizations move at the speed of the cloud and innovate at a breakneck pace, errors and data exposure are inevitable if the necessary technologies are not in place. 2.3 Citybee Lithuanian police are investigating after 110,000 peoples personal information was exposed to an internet hacker website. CityBee, a car-sharing service, revealed that the breach compromised the records and information of thousands of its clients. euronews.com - Thousands of CityBee users have their personal data leaked online. As the attacker stated, CityBee was using a service provided by Microsoft called Azure Blob, which is used as storage of some sorts. Now Microsoft allows you to secure those blobs with authentication, which Citybee for some reason chose not to. He was able to search CityBee in a DNS record called CNAME which linked to their azure blob and other things like their website. Even a step-by-step instruction was provided by the hacker. Essentially, it was a BACPAC file named CitybeeProduction, which contained the metadata and data from the database. Citybee also used a very weak SHA-1 encryption algorithm for passwords without any salt added. Citybee production database leak - image source https://cybernews.com/ "],["public-cloud.html", "Chapter 3 Public Cloud 3.1 Public Cloud Security 3.2 Infrastructure as Code", " Chapter 3 Public Cloud 3.1 Public Cloud Security Cloud security is a critical matter. Most companies worry that highly sensitive data and intellectual property may be exposed through accidental leaks or due to increasingly sophisticated cyber attacks. Gartner predicts that through 2025, 99% of cloud security failures will be the customers fault. Moreover, having a solid cloud security stance helps organizations achieve other benefits, such as: Lower costs Reduced ongoing operational and administrative expenses Scalability Increased reliability and availability DevOps way of working Despite bringing many benefits, the cloud computing paradigm imposes serious concerns in terms of security and privacy, which are considered hurdles in the adoption of the cloud at a very large scale (Alghofaili et al. 2021). Security issues are depended on the cloud provider, service user, instance (Y. Sun et al. 2014), and the delivery model, PaaS, IaaS, and SaaS (X. Sun 2018). Data stored in the public cloud would face both outside attacks and inside attacks (Shi 2018). Data loss and leakage were the biggest security concern, with 44% of organizations seeing data loss as one of their top three focus areas. Two-thirds of organizations leave back doors open to attackers leading to an accidental exposure through misconfiguration. Security gaps in misconfigurations were exploited in 66% of attacks (Sophos 2020). How criminals are getting in, source - sophos.com Zero Trust security model enables securing cloud-native applications by encrypting all network communication, authenticating, and authorizing every request. The traditional trust management mechanisms represent a static trust relationship that falls deficit while meeting up the dynamic requirement of cloud services. (Mehraj and Banday 2020). In order to achieve a true zero-trust security model in the cloud, a combination of network and identity permission policies should be in place. The Zero Trust eXtended (ZTX) Ecosystem, Forrester Research, Inc., source - juniper.net To adequately address the modern dynamic threat environment requires(Agency 2021): Coordinated and aggressive system monitoring, system management, and defensive operations capabilities. Assuming all requests for critical resources and all network traffic may be malicious. Assuming all devices and infrastructure may be compromised. Accepting that all access approvals to critical resources incur a risk Some security recommendations for network security can be summarized as follows (Alghofaili et al. 2021): Secure communication techniques should be adopted: HTTPS for web applications, transmission channel must be encrypted by TLS Additional monitoring should be done (manual, automatic, ML based) Other public security services such as web application firewalls (WAF), virtual firewalls, virtual bastion machines, virtual host protection, and virtual database audit systems could be used 3.2 Infrastructure as Code There was a significant shift in development, deployment, and software application management during the past decade. The new approach is called Development Operations (DevOps) where Infrastructure as Code (IaC) plays a core role. While manual configurations in the Cloud context was a norm, nowadays it is fully automated using blueprints that are easily interpretable by machines. Moreover, IaC approach allows a faster and homogeneous configuration for the whole infrastructure. Usually, it is utilized by a specific declarative language (TerraForm, CloudFormation, Puppet) that allows users to describe the desired state of the infrastructure. This significantly reduces the time, complexity and helps to provision the infrastructure from the security, management, and costs perspectives. The whole idea behind IaC is simple - developers can write declarative statements that define the infrastructure necessary to run the code as opposed to writing a ticket/creating a task for administrators. Reproducibility and transparency come as a side effects. Infrastructure as Code Survey, source - thenewstack.io Terraform is one of the most popular ways to implement this pipeline, especially in a Cloud context. It is an open-source tool that lets you provision Google Cloud resources with declarative configuration files-resources such as virtual machines, containers, storage, and networking. It lets users manage Terraform configuration files in source control to maintain an ideal provisioning state for testing, production, and other environments. (Almuairfi and Alenezi 2020) References "],["project-scope.html", "Chapter 4 Project Scope 4.1 Platform for anatical applications 4.2 Kubernetes and Docker 4.3 Shiny Server on insecure machines", " Chapter 4 Project Scope 4.1 Platform for anatical applications 4.2 Kubernetes and Docker While virtualized applications are highly preferred as opposed to IaaS approach (virtual machines), it makes sense to dig deeper in kubernetes and docker setup, regardless of the chosen managed service. Cloud Strategy - image source Flexera Kubernetes was founded by Ville Aikas, Joe Beda, Brendan Burns, and Craig McLuckie in collaboration with Google engineers Brian Grant and Tim Hockin in mid-2014. Googles Borg system heavily influenced kubernetes design (Verma et al. 2015) (Burns et al. 2016). While the Borg project was implemented entirely in C++, Kubernetes was rewritten in Go language. The main goal of kubernetes was to build on the capabilities of containers and provide significant gains in programmer productivity while easing the management of the system. Container evolution - kubernetes.io Kubernetes is the most popular container orchestration platform that enables users to create and run multiple containers in cloud environments. Kubernetes offers resource management to isolate the resource usage of containers on a host server because performance isolation is an important factor in terms of service quality. The components of a Kubernetes cluster - kubernetes.io Terraform example, source - cloud.google.com 4.3 Shiny Server on insecure machines Computer networks are prone to attacks and it has a wide range of attacks associated with them. Cloud is not an exception and even holds more risk. It can be prone to Denial-of-service, Eavesdropping, Host Attacks, Password Guessing, Protocol-based, and Social Engineering attacks (Chopra 2016). As an experiment, the firewall was opened to the whole world and network activity was monitored for one week. While the activity in the Compute Instance (Shiny Server hosted on a Virtual Server) was marginal, the exposed Shiny Server instance on Google Kubernetes Cluster was scanned extensively. This could be due to the rules on how Google generates IP addresses for corresponding instances. Moreover, GKE was exposed on port 80 which is a standard HTTP port, while the standard port of shiny server (3838) was used for Compute Instance, which is not that common configuration. Incoming Requests While the majority of the requests came from the USA, applications from China and Russia also scanned our exposed application considerably. These scans also are not centralized but are rather done by individuals or companies which specialize in data mining and web crawling. Some requests are also received from Lithuania, CGates Internet Service Provider. Incoming Requets from different cities Some of the IPs were crossed check with a publicly available IP database. These IP addresses, especially from China and Russia, were already reported a number of times and are indicated as abusive. Blacklisted IPs - source https://www.abuseipdb.com/ The analysis proves that an incorrectly configured firewall poses one of the most significant security risks. Misconfigured applications could serve as a back door and is a low handing fruit for hackers - e.g. it is easy to run a port scan for a specific IP range and use a collection of scripts/exploits to check whether there are any holes in the application. If any sensitive data where General Data Protection Regulation is not applied (i.e. USA, China, Russia). References "],["security-considerations.html", "Chapter 5 Security considerations 5.1 Certificates and TLS 5.2 Auth 5.3 Network", " Chapter 5 Security considerations 5.1 Certificates and TLS Transport Layer Security (TLS) encrypts data sent over the Internet to ensure that eavesdroppers and hackers are unable to see what you transmit which is particularly useful for private and sensitive information such as passwords, credit card numbers, and personal correspondence. This page explains what TLS is, how it works, and why you should deploy it. TLS evolved from Secure Socket Layers (SSL) which was originally developed by Netscape Communications Corporation in 1994 to secure web sessions. SSL 1.0 was never publicly released, whilst SSL 2.0 was quickly replaced by SSL 3.0 on which TLS is based. Data has historically been transmitted unencrypted over the Internet, and where encryption was used, it was typically employed in a piecemeal fashion for sensitive information such as passwords or payment details. Without TLS, sensitive information such as logins, credit card details and personal details can easily be gleaned by others, but also browsing habits, e-mail correspondence, online chats and conferencing calls can be monitored. By enabling client and server applications to support TLS, it ensures that data transmitted between them is encrypted with secure algorithms and not viewable by third parties. TLS is the most widely-used cryptographic protocol on the Internet. It comprises the TLS Handshake Protocol, responsible for authentication and key establishment, and the TLS Record Protocol, which takes care of subsequent use of those keys to protect bulk data. In this paper, we present the most complete analysis to date of the TLS Handshake protocol and its application to data encryption (in the Record Protocol). We show how to extract a key-encapsulation mechanism (KEM) from the TLS Handshake Protocol, and how the security of the entire TLS protocol follows from security properties of this KEM when composed with a secure authenticated encryption scheme in the Record Protocol. https://freecontent.manning.com/how-does-tls-work/ Handshake: Negotiation. TLS is highly configurable. Both a client and a server can be configured to negotiate a range of SSL and TLS versions, as well as a menu of acceptable cryptographic algorithms. The negotiation phase of the handshake aims at finding common ground between the clients and the servers configurations, in order to securely connect the two peers. Key exchange. The whole point of the handshake is to perform a key exchange between the two participants. What key exchange algorithm to use? This is one of the things decided as part of the negotiation process. Authentication. It is trivial for a MITM attacker to impersonate any side of a key exchange. For this reason, key exchanges must be authenticated. (Your browser must have a way to make sure that it is talking to google.com and not your Internet service provider, for example.) Session Resumption. As browsers often connect to the same websites again and again, key exchanges can be costly and slow down a users experience. For this reason, mechanisms to fast-track secure sessions without redoing a key exchange are integrated into TLS. RSA and the Diffie-Hellman Key Exchange are the two most popular encryption algorithms that solve the same problem in different ways. In a nutshell, Diffie Hellman approach generates a public and private key on both sides of the transaction, but only shares the public key. Unlike Diffie-Hellman, the RSA algorithm can be used for signing digital signatures as well as symmetric key exchange, but it does require the exchange of a public key beforehand. https://www.researchgate.net/figure/TLS-key-transport-with-RSA_fig1_234811497 5.2 Auth OAuth 2.0: If youve ever signed up to a new application and agreed to let it automatically source new contacts via Facebook or your phone contacts, then youve likely used OAuth 2.0. This standard provides secure delegated access. That means an application can take actions or access resources from a server on behalf of the user, without them having to share their credentials. It does this by allowing the identity provider (IdP) to issue tokens to third-party applications with the users approval. OpenID Connect: If youve used your Google to sign in to applications like YouTube, or Facebook to log into an online shopping cart, then youre familiar with this authentication option. OpenID Connect is an open standard that organizations use to authenticate users. IdPs use this so that users can sign in to the IdP, and then access other websites and apps without having to log in or share their sign-in information. SAML: Youve more likely experienced SAML authentication in action in the work environment. For example, it enables you to log into your corporate intranet or IdP and then access numerous additional services, such as Salesforce, Box, or Workday, without having to re-enter your credentials. SAML is an XML-based standard for exchanging authentication and authorization data between IdPs and service providers to verify the users identity and permissions, then grant or deny their access to services. 5.2.1 Authentication 5.2.2 Authorization 5.2.3 SAML 5.3 Network "],["implementation-in-gcp.html", "Chapter 6 Implementation in GCP 6.1 Conteinarization 6.2 Shiny App security features 6.3 Cloud Security", " Chapter 6 Implementation in GCP 6.1 Conteinarization gcloud auth login --project shiny-cloud-345816 PROJECTID=$(gcloud config get-value project) docker build . -t gcr.io/$PROJECTID/signin docker push gcr.io/$PROJECTID/signin 6.1.1 Cloud Run 6.1.2 GKE 6.2 Shiny App security features 6.2.1 Shiny server authentication 6.2.2 Shiny authorization 6.3 Cloud Security 6.3.1 Firewalls 6.3.2 DNS 6.3.3 Certificates 6.3.4 Identity aware proxy 6.3.5 Audit gcloud beta dns --project=shiny-cloud-345816 managed-zones create shinycloud-online --description=&quot;&quot; --dns-name=&quot;shinycloud.online.&quot; --visibility=&quot;public&quot; --dnssec-state=&quot;off&quot; --log-dns-queries "],["references.html", "References", " References "],["404.html", "Page not found", " Page not found The page you requested cannot be found (perhaps it was moved or renamed). You may want to try searching to find the page's new location, or use the table of contents to find the page you are looking for. "]]
